{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of the data samples \n",
      "     Label                                             Review\n",
      "0   fresh   Manakamana doesn't answer any questions, yet ...\n",
      "1   fresh   Wilfully offensive and powered by a chest-thu...\n",
      "2  rotten   It would be difficult to imagine material mor... \n",
      "\n",
      "Dimension of the data set:\n",
      " (40000, 2) \n",
      "\n",
      "Distribution of the data set:\n",
      " Label\n",
      "fresh     0.500175\n",
      "rotten    0.499825\n",
      "Name: proportion, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read CSV\n",
    "fresh_rotten_data_set = pd.read_csv('./rt_reviews.csv',names=['Label', 'Review'], encoding=\"windows_1258\", header=0, nrows = 40000)\n",
    "print(\"Examples of the data samples \\n\", fresh_rotten_data_set.head(3), \"\\n\")\n",
    "print(\"Dimension of the data set:\\n\", fresh_rotten_data_set.shape, \"\\n\")\n",
    "print(\"Distribution of the data set:\\n\", fresh_rotten_data_set['Label'].value_counts(normalize=True), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribtuion of the training data set:\n",
      " Label\n",
      "fresh     0.500062\n",
      "rotten    0.499937\n",
      "Name: proportion, dtype: float64 32000 \n",
      "\n",
      "Distribtuion of the testing data set:\n",
      " Label\n",
      "fresh     0.500625\n",
      "rotten    0.499375\n",
      "Name: proportion, dtype: float64 8000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform train/test split\n",
    "review_texts, labels = fresh_rotten_data_set.Review, fresh_rotten_data_set.Label\n",
    "from sklearn.model_selection import train_test_split\n",
    "review_texts_train, review_texts_test, labels_train, labels_test = train_test_split(review_texts, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "review_texts_train = review_texts_train.reset_index(drop=True)\n",
    "labels_train = labels_train.reset_index(drop=True)\n",
    "\n",
    "review_texts_test = review_texts_test.reset_index(drop=True)\n",
    "labels_test = labels_test.reset_index(drop=True)\n",
    "\n",
    "print(\"Distribtuion of the training data set:\\n\", labels_train.value_counts(normalize=True),  labels_train.shape[0], \"\\n\")\n",
    "\n",
    "print(\"Distribtuion of the testing data set:\\n\", labels_test.value_counts(normalize=True), labels_test.shape[0], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish---------------------------------------------------------------- 352000\n",
      "Features (the number of all possible words in the trainning data):\n",
      " 66084 \n",
      "\n",
      "Examples of the training data \n",
      "     Label                                             Review  sea\"  \\\n",
      "0  rotten   This interminable farrago feels like swimming...     0   \n",
      "1  rotten   [Ferrell's] humor is cut off at the knees by ...     0   \n",
      "2   fresh   The IRA-flavored Death Wish remake we didn't ...     0   \n",
      "\n",
      "   underplays  depp  preferable.  lows;  infinite,  lady  slums,  ...  \\\n",
      "0           0     0            0      0          0     0       0  ...   \n",
      "1           0     0            0      0          0     0       0  ...   \n",
      "2           0     0            0      0          0     0       0  ...   \n",
      "\n",
      "   english,  off-camera.  arouses  plotnick's  strangeness,  hurry,  relieved  \\\n",
      "0         0            0        0           0             0       0         0   \n",
      "1         0            0        0           0             0       0         0   \n",
      "2         0            0        0           0             0       0         0   \n",
      "\n",
      "   shadowing  express,\"  suffers  \n",
      "0          0          0        0  \n",
      "1          0          0        0  \n",
      "2          0          0        0  \n",
      "\n",
      "[3 rows x 66086 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def reviewTextToVectors(review_texts):\n",
    "    review_texts = review_texts.str.replace('\\W', '')\n",
    "    review_texts = review_texts.str.lower()\n",
    "    review_texts = review_texts.str.split()\n",
    "\n",
    "    vocabulary = []\n",
    "    for review in review_texts:\n",
    "        for word in review:\n",
    "            vocabulary.append(word)\n",
    "    \n",
    "    # list -> set for get only unique value\n",
    "    vocabulary = list(set(vocabulary))\n",
    "\n",
    "    \n",
    "    word_counts_per_review = {}\n",
    "    # i = 0\n",
    "    for unique_word in vocabulary:\n",
    "        word_counts_per_review[unique_word] = [0] * len(review_texts)\n",
    "        # i += 1\n",
    "        # if i % 1000 == 0:\n",
    "        #     print(i)\n",
    "    print(\"finish----------------------------------------------------------------\", len(review_texts) * len(review_texts[0]))\n",
    "    \n",
    "    for index, review in enumerate(review_texts):\n",
    "        for word in review:\n",
    "            word_counts_per_review[word][index] += 1\n",
    "\n",
    "    return word_counts_per_review, vocabulary\n",
    "\n",
    "\n",
    "    # word_counts_per_review = {unique_word: [0] * len(review_texts) for unique_word in vocabulary}\n",
    "    # print(type(word_counts_per_review))\n",
    "\n",
    "    # print(word_counts_per_review)\n",
    "\n",
    "    # return word_counts_per_review\n",
    "\n",
    "\n",
    "\n",
    "word_counts_per_review, vocabulary = reviewTextToVectors(review_texts_train)\n",
    "x_train = pd.DataFrame(word_counts_per_review)\n",
    "print(\"Features (the number of all possible words in the trainning data):\\n\", len(vocabulary), \"\\n\")\n",
    "\n",
    "\n",
    "training_data_set = pd.concat([labels_train, review_texts_train, x_train], axis=1)\n",
    "print(\"Examples of the training data \\n\", training_data_set.head(3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (the number of all possible words in the trainning data):\n",
      " 66084 \n",
      "\n",
      "Examples of the training data \n",
      "     Label                                             Review  sea\"  \\\n",
      "0  rotten   This interminable farrago feels like swimming...     0   \n",
      "1  rotten   [Ferrell's] humor is cut off at the knees by ...     0   \n",
      "2   fresh   The IRA-flavored Death Wish remake we didn't ...     0   \n",
      "\n",
      "   underplays  depp  preferable.  lows;  infinite,  lady  slums,  ...  \\\n",
      "0           0     0            0      0          0     0       0  ...   \n",
      "1           0     0            0      0          0     0       0  ...   \n",
      "2           0     0            0      0          0     0       0  ...   \n",
      "\n",
      "   english,  off-camera.  arouses  plotnick's  strangeness,  hurry,  relieved  \\\n",
      "0         0            0        0           0             0       0         0   \n",
      "1         0            0        0           0             0       0         0   \n",
      "2         0            0        0           0             0       0         0   \n",
      "\n",
      "   shadowing  express,\"  suffers  \n",
      "0          0          0        0  \n",
      "1          0          0        0  \n",
      "2          0          0        0  \n",
      "\n",
      "[3 rows x 66086 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Features (the number of all possible words in the trainning data):\\n\", len(vocabulary), \"\\n\")\n",
    "\n",
    "\n",
    "# training_data_set = pd.concat([labels_train, review_texts_train, x_train], axis=1)\n",
    "print(\"Examples of the training data \\n\", training_data_set.head(3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our estimate of P(y=rotten) is  0.4999375\n",
      "Our estimate of P(y=fresh) is  0.5000625\n"
     ]
    }
   ],
   "source": [
    "x_train_rotten = x_train[labels_train == 'rotten']\n",
    "x_train_fresh = x_train[labels_train == 'fresh']\n",
    "\n",
    "#Estimate P(y=rotten) and P(y=fresh)\n",
    "p_rotten = len(x_train_rotten)/len(x_train)\n",
    "print(\"Our estimate of P(y=rotten) is \", p_rotten)\n",
    "\n",
    "p_fresh = len(x_train_fresh)/len(x_train)\n",
    "print(\"Our estimate of P(y=fresh) is \", p_fresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate parameters\n",
    "theta_rotten = {unique_word:0 for unique_word in vocabulary}\n",
    "theta_fresh =  {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "#Estimate the probability distribution of selecting each word\n",
    "rotten_word_count = np.sum(x_train_rotten.values)\n",
    "fresh_word_count = np.sum(x_train_fresh.values)\n",
    "for word in vocabulary:\n",
    "    theta_rotten[word] = (sum(x_train_rotten[word]) + 1) / (rotten_word_count +1)\n",
    "    theta_fresh[word] = (sum(x_train_fresh[word]) +1) / (fresh_word_count +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToVector(message):\n",
    "    message = re.sub('\\W', ' ', message) #Remove punctuation (comment: re.sub() is like a str.replace())\n",
    "    message = message.lower().split()\n",
    "\n",
    "    vocabulary = []\n",
    "    for word in message:\n",
    "        vocabulary.append(word)\n",
    "    vocabulary = list(set(vocabulary))\n",
    "\n",
    "    word_counts = {unique_word: 0 for unique_word in vocabulary}\n",
    "\n",
    "    for word in message:\n",
    "        word_counts[word] += 1\n",
    "\n",
    "    return word_counts, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classify(review_texts):\n",
    "    x_test, vocabulary = textToVector(review_texts)\n",
    "\n",
    "    p_rotten_given_review = p_rotten\n",
    "    p_fresh_given_review = p_fresh\n",
    "\n",
    "    for word in x_test:\n",
    "        if word in theta_rotten:\n",
    "            p_rotten_given_review *= theta_rotten[word]\n",
    "        if word in theta_fresh:\n",
    "            p_fresh_given_review *= theta_fresh[word]\n",
    "\n",
    "\n",
    "    p_rotten_given_review = math.log(p_rotten_given_review)\n",
    "    p_fresh_given_review =  math.log(p_fresh_given_review)\n",
    "    # print('Estimate of log(P(rotten|message=',  review_texts, ')) =', p_rotten_given_review)\n",
    "    # print('Estimate of log(P(fresh|message=',  review_texts, ')) =', p_fresh_given_review)\n",
    "\n",
    "    isRotten = True\n",
    "    if(p_rotten_given_review > p_fresh_given_review):\n",
    "        isRotten = True\n",
    "    else:\n",
    "        isRotten = False\n",
    "    return isRotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(review_texts, labels):\n",
    "    mistakes = 0\n",
    "    for i, message in enumerate(review_texts):\n",
    "        isRotten = naive_bayes_classify(message)\n",
    "        if isRotten and labels[i] != \"rotten\":\n",
    "            mistakes += 1\n",
    "        elif not isRotten and labels[i] == \"rotten\":\n",
    "            mistakes += 1\n",
    "    return (len(review_texts)-mistakes)/len(review_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.85703125\n",
      "Generalization accuracy: 0.758625\n"
     ]
    }
   ],
   "source": [
    "#Calculate loss on training data\n",
    "print(\"Training accuracy:\", score(review_texts_train, labels_train))\n",
    "#Calculate generalization loss\n",
    "print(\"Generalization accuracy:\", score(review_texts_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review):\n",
    "    if naive_bayes_classify(review) == True:\n",
    "        print(\"rotten: \",review)\n",
    "    else:\n",
    "        print(\"fresh: \",review)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fresh:  Godzilla X Kong: The New Empire is a fun, albeit flawed, addition to the Monsterverse.\n",
      "rotten:  Dumbed-down and stripped of the symbolic subtext of the earlier movies, the picture is not without seat-shuddering thrills, but it’s like a tag-team wrestling bout for monsters rather than a picture with meaning and even a modicum of thought.\n"
     ]
    }
   ],
   "source": [
    "predict(\"Godzilla X Kong: The New Empire is a fun, albeit flawed, addition to the Monsterverse.\")\n",
    "predict(\"Dumbed-down and stripped of the symbolic subtext of the earlier movies, the picture is not without seat-shuddering thrills, but it’s like a tag-team wrestling bout for monsters rather than a picture with meaning and even a modicum of thought.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
