{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=20>นายกฤษฏ์ อัศวนิรมล รหัสนิสิต 6310450786</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of the data samples \n",
      "     Label                                             Review\n",
      "0   fresh   Manakamana doesn't answer any questions, yet ...\n",
      "1   fresh   Wilfully offensive and powered by a chest-thu...\n",
      "2  rotten   It would be difficult to imagine material mor... \n",
      "\n",
      "Dimension of the data set:\n",
      " (40000, 2) \n",
      "\n",
      "Distribution of the data set:\n",
      " Label\n",
      "fresh     0.500175\n",
      "rotten    0.499825\n",
      "Name: proportion, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read CSV\n",
    "fresh_rotten_data_set = pd.read_csv('./rt_reviews.csv',names=['Label', 'Review'], encoding=\"windows_1258\", header=0, nrows = 40000)\n",
    "print(\"Examples of the data samples \\n\", fresh_rotten_data_set.head(3), \"\\n\")\n",
    "print(\"Dimension of the data set:\\n\", fresh_rotten_data_set.shape, \"\\n\")\n",
    "print(\"Distribution of the data set:\\n\", fresh_rotten_data_set['Label'].value_counts(normalize=True), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "fresh     20007\n",
       "rotten    19993\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_rotten_data_set['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribtuion of the training data set:\n",
      " Label\n",
      "fresh     0.500062\n",
      "rotten    0.499937\n",
      "Name: proportion, dtype: float64 32000 \n",
      "\n",
      "Distribtuion of the testing data set:\n",
      " Label\n",
      "fresh     0.500625\n",
      "rotten    0.499375\n",
      "Name: proportion, dtype: float64 8000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform train/test split\n",
    "review_texts, labels = fresh_rotten_data_set.Review, fresh_rotten_data_set.Label\n",
    "review_texts_train, review_texts_test, labels_train, labels_test = train_test_split(review_texts, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "review_texts_train = review_texts_train.reset_index(drop=True)\n",
    "labels_train = labels_train.reset_index(drop=True)\n",
    "\n",
    "review_texts_test = review_texts_test.reset_index(drop=True)\n",
    "labels_test = labels_test.reset_index(drop=True)\n",
    "\n",
    "print(\"Distribtuion of the training data set:\\n\", labels_train.value_counts(normalize=True),  labels_train.shape[0], \"\\n\")\n",
    "\n",
    "print(\"Distribtuion of the testing data set:\\n\", labels_test.value_counts(normalize=True), labels_test.shape[0], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (the number of all possible words in the trainning data):\n",
      " 66084 \n",
      "\n",
      "Examples of the training data \n",
      "     Label                                             Review  despuï¿½ï¿½s  \\\n",
      "0  rotten   This interminable farrago feels like swimming...             0   \n",
      "1  rotten   [Ferrell's] humor is cut off at the knees by ...             0   \n",
      "2   fresh   The IRA-flavored Death Wish remake we didn't ...             0   \n",
      "\n",
      "   metal-against-metal  fort  battles,  motor,  scorn  mission\"  bed-of-roses  \\\n",
      "0                    0     0         0       0      0         0             0   \n",
      "1                    0     0         0       0      0         0             0   \n",
      "2                    0     0         0       0      0         0             0   \n",
      "\n",
      "   ...  halt  surpass  failure,  cutter's  spliced  shading  maddest  \\\n",
      "0  ...     0        0         0         0        0        0        0   \n",
      "1  ...     0        0         0         0        0        0        0   \n",
      "2  ...     0        0         0         0        0        0        0   \n",
      "\n",
      "   \"identity  1982  denizens  \n",
      "0          0     0         0  \n",
      "1          0     0         0  \n",
      "2          0     0         0  \n",
      "\n",
      "[3 rows x 66086 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def reviewTextToVectors(review_texts):\n",
    "    review_texts = review_texts.str.replace('\\W', '')\n",
    "    review_texts = review_texts.str.lower()\n",
    "    review_texts = review_texts.str.split()\n",
    "\n",
    "    vocabulary = []\n",
    "    for review in review_texts:\n",
    "        for word in review:\n",
    "            vocabulary.append(word)\n",
    "    \n",
    "    # list -> set for get only unique value\n",
    "    vocabulary = list(set(vocabulary))\n",
    "    \n",
    "    word_counts_per_review = {}\n",
    "    for unique_word in vocabulary:\n",
    "        word_counts_per_review[unique_word] = [0] * len(review_texts)\n",
    "\n",
    "    for index, review in enumerate(review_texts):\n",
    "        for word in review:\n",
    "            word_counts_per_review[word][index] += 1\n",
    "\n",
    "    return word_counts_per_review, vocabulary\n",
    "\n",
    "\n",
    "word_counts_per_review, vocabulary = reviewTextToVectors(review_texts_train)\n",
    "x_train = pd.DataFrame(word_counts_per_review)\n",
    "print(\"Features (the number of all possible words in the trainning data):\\n\", len(vocabulary), \"\\n\")\n",
    "\n",
    "\n",
    "training_data_set = pd.concat([labels_train, review_texts_train, x_train], axis=1)\n",
    "print(\"Examples of the training data \\n\", training_data_set.head(3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our estimate of P(y=rotten) is  0.4999375\n",
      "Our estimate of P(y=fresh) is  0.5000625\n"
     ]
    }
   ],
   "source": [
    "x_train_rotten = x_train[labels_train == 'rotten']\n",
    "x_train_fresh = x_train[labels_train == 'fresh']\n",
    "\n",
    "#Estimate P(y=rotten) and P(y=fresh)\n",
    "p_rotten = len(x_train_rotten)/len(x_train)\n",
    "print(\"Our estimate of P(y=rotten) is \", p_rotten)\n",
    "\n",
    "p_fresh = len(x_train_fresh)/len(x_train)\n",
    "print(\"Our estimate of P(y=fresh) is \", p_fresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate parameters\n",
    "theta_rotten = {unique_word:0 for unique_word in vocabulary}\n",
    "theta_fresh =  {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "#Estimate the probability distribution of selecting each word\n",
    "rotten_word_count = np.sum(x_train_rotten.values)\n",
    "fresh_word_count = np.sum(x_train_fresh.values)\n",
    "for word in vocabulary:\n",
    "    theta_rotten[word] = (sum(x_train_rotten[word]) + 1) / (rotten_word_count + (1 * len(vocabulary)))\n",
    "    theta_fresh[word] = (sum(x_train_fresh[word]) + 1) / (fresh_word_count +(1 * len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "def textToVector(message):\n",
    "    message = re.sub('\\W', ' ', message) #Remove punctuation (comment: re.sub() is like a str.replace())\n",
    "    message = message.lower().split()\n",
    "\n",
    "    vocabulary = []\n",
    "    for word in message:\n",
    "        vocabulary.append(word)\n",
    "    vocabulary = list(set(vocabulary))\n",
    "\n",
    "    word_counts = {unique_word: 0 for unique_word in vocabulary}\n",
    "\n",
    "    for word in message:\n",
    "        word_counts[word] += 1\n",
    "\n",
    "    return word_counts, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def naive_bayes_classify(review_texts):\n",
    "    x_test, vocabulary = textToVector(review_texts)\n",
    "\n",
    "    p_rotten_given_review = p_rotten\n",
    "    p_fresh_given_review = p_fresh\n",
    "\n",
    "    for word in x_test:\n",
    "        if word in theta_rotten:\n",
    "            p_rotten_given_review *= theta_rotten[word]\n",
    "        if word in theta_fresh:\n",
    "            p_fresh_given_review *= theta_fresh[word]\n",
    "\n",
    "\n",
    "    p_rotten_given_review = math.log(p_rotten_given_review)\n",
    "    p_fresh_given_review =  math.log(p_fresh_given_review)\n",
    "    # print('Estimate of log(P(rotten|message=',  review_texts, ')) =', p_rotten_given_review)\n",
    "    # print('Estimate of log(P(fresh|message=',  review_texts, ')) =', p_fresh_given_review)\n",
    "\n",
    "    isRotten = True\n",
    "    if(p_rotten_given_review > p_fresh_given_review):\n",
    "        isRotten = True\n",
    "    else:\n",
    "        isRotten = False\n",
    "    return isRotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(review_texts, labels):\n",
    "    mistakes = 0\n",
    "    for i, message in enumerate(review_texts):\n",
    "        isRotten = naive_bayes_classify(message)\n",
    "        if isRotten and labels[i] != \"rotten\":\n",
    "            mistakes += 1\n",
    "        elif not isRotten and labels[i] == \"rotten\":\n",
    "            mistakes += 1\n",
    "    return (len(review_texts)-mistakes)/len(review_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.85684375\n",
      "Generalization accuracy: 0.75825\n"
     ]
    }
   ],
   "source": [
    "#Calculate loss on training data\n",
    "print(\"Training accuracy:\", score(review_texts_train, labels_train))\n",
    "#Calculate generalization loss\n",
    "print(\"Generalization accuracy:\", score(review_texts_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(testData):\n",
    "    for review in testData:\n",
    "        predict = \"\"\n",
    "        result = \"wrong\"\n",
    "        if naive_bayes_classify(review[0]) == True:\n",
    "            predict = \"rotten\"\n",
    "        else:\n",
    "            predict = \"fresh\"\n",
    "        if review[1] == \"\" :\n",
    "            review[1] = \"-\"\n",
    "            result = \"-\"\n",
    "        elif review[1] == predict:\n",
    "            result = \"correct\"\n",
    "        print(\"Answer: \",review[1], \", Predict: \", predict, \" | \",result)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  - , Predict:  fresh  |  -\n",
      "Answer:  rotten , Predict:  rotten  |  correct\n"
     ]
    }
   ],
   "source": [
    "testData = [\n",
    "    [\"Godzilla X Kong: The New Empire is a fun, albeit flawed, addition to the Monsterverse.\", \"\"],\n",
    "    [\"As much fun as it is to watch the Titans fight... at some point you go like: 'what's the point of this'.\", \"rotten\"]\n",
    "]\n",
    "predict(testData)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
